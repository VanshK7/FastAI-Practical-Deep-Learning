{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch, numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleaning the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(path/'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the sum of NA values for all columns\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing NA values with the mode (most common value)\n",
    "modes = df.mode().iloc[0]           # getting the 1st mode as if there are multiple modes, it returns all of them\n",
    "modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)          # Replacing the values in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()                 # No more NA values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=(np.number))        # Getting a general idea of our data (inc. only columns with numeric data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Fare'].hist()           # Most fares between $0-50, with a few fares between $450-500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our dataset, `Fare` is a long tailed distribution.\n",
    "\n",
    "Some models, including regression models and neural networks do not 'like' long tailed distributions. They usually perform badly when long tailed distribution exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sure-shot way to fix a long tailed distribution is to find the log as log makes big values 'less big' while not affecting the smaller values much.\n",
    "We normally take log of values which grow exponentially, e.g. population, money, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the log of the value of Fare + 1 as:\n",
    "1. log(0) is undefined, so, there may be issues if the value of Fare is 0\n",
    "2. Taking Fare + 1 instead of Fare helps us avoid take the log of very small numbers (which usually results in large negative numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LogFare'].hist()        # Now the distribution is much more 'centered'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Converting non-numeric columns to numeric/boolean columns**\n",
    "\n",
    "e.g. The column `Sex` has 2 values: male and female, so dividing the column `Sex` into 2 boolean columns:\n",
    "1. `Sex_male`\n",
    "2. `Sex_female`\n",
    "\n",
    "If the passenger is male, `Sex_male` will be 1 and `Sex_female` will be 0.\n",
    "\n",
    "We divide it into 2 columns instead of substituting the number 0 in place of male and 1 in place of female for interpretability purposes. If numeric values were provided in the same column, the model may provide a coeffecient for the `Sex` column as 0.2, but, 0.2  doesn't imply male or female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look into the non-numeric columns\n",
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket',\n",
       "       'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male', 'Pclass_1',\n",
       "       'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df, columns=['Sex', 'Pclass', 'Embarked'])        # Converting string columns to boolean columns\n",
    "df.columns              # You can view the added columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_cols=['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                                 Name  \\\n",
       "0            1         0                              Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)   \n",
       "2            3         1                               Heikkinen, Miss. Laina   \n",
       "3            4         1         Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                             Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare    Cabin   LogFare  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500  B96 B98  2.110213   \n",
       "1  38.0      1      0          PC 17599  71.2833      C85  4.280593   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250  B96 B98  2.188856   \n",
       "3  35.0      1      0            113803  53.1000     C123  3.990834   \n",
       "4  35.0      0      0            373450   8.0500  B96 B98  2.202765   \n",
       "\n",
       "   Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n",
       "0           0         1         0         0         1           0           0   \n",
       "1           1         0         1         0         0           1           0   \n",
       "2           1         0         0         0         1           0           0   \n",
       "3           1         0         1         0         0           0           0   \n",
       "4           0         1         0         0         1           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "# Converting our dependent variable - Survived into a tensor\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing our independent variables and converting them to tensors\n",
    "indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n",
    "\n",
    "t_indep  = tensor(df[indep_cols].values, dtype=torch.float)         # data type should be float if we are going to multiply things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape               # Gives the size and dimensionality of the vector, VVV important attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_indep.shape)          # Gives the rank of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up a Linear Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)           # Can be any random number, when seed is same, we get the same 'random' numbers\n",
    "\n",
    "# Number of coefficients = number of columns\n",
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.rand(n_coeff)-0.5            # To initialize random numbers between -0.5 and 0.5 for each coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.4099,  0.4150, -0.0000,  ..., -0.0000,  0.0000,  0.0936],\n",
       "        [14.5262,  0.4150, -0.0000,  ..., -0.3668,  0.0000,  0.0000],\n",
       "        [ 9.9390,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0936],\n",
       "        ...,\n",
       "        [ 9.1745,  0.4150, -0.2343,  ..., -0.0000,  0.0000,  0.0936],\n",
       "        [ 9.9390,  0.0000, -0.0000,  ..., -0.3668,  0.0000,  0.0000],\n",
       "        [12.2326,  0.0000, -0.0000,  ..., -0.0000,  0.4346,  0.0000]])"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep * coeffs    # We perform broadcasting - multiplying each coefficient by each value of each independent variable\n",
    "\n",
    "# These are not normalized, values for most columns between -1 and 1 but the 1st column has larger values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, indices = t_indep.max(dim=0)          # dim=0 indicates we want maximum by rows (max for each column)\n",
    "# vals stores the maximum values for each column and indices stores the index posn of the maximum values\n",
    "\n",
    "# Normalizing\n",
    "t_indep = t_indep/vals          # Again we perform broadcasting, but this time we divide each value in t_indep by each value in vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1051,  0.0519, -0.0000,  ..., -0.0000,  0.0000,  0.0936],\n",
       "        [ 0.1816,  0.0519, -0.0000,  ..., -0.3668,  0.0000,  0.0000],\n",
       "        [ 0.1242,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0936],\n",
       "        ...,\n",
       "        [ 0.1147,  0.0519, -0.0390,  ..., -0.0000,  0.0000,  0.0936],\n",
       "        [ 0.1242,  0.0000, -0.0000,  ..., -0.3668,  0.0000,  0.0000],\n",
       "        [ 0.1529,  0.0000, -0.0000,  ..., -0.0000,  0.4346,  0.0000]])"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep * coeffs        # Now the values are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)            # Summing up the coefficient values gives us the predicted target value, will be very inaccurate as coefficients are random numbers right now\n",
    "\n",
    "# axis=1 ensures that we find out the sum of values in columns, getting a prediction for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7371, 0.0391, 0.9206, 0.4639, 0.7542, 1.0459, 0.2906, 0.7982, 0.9089,\n",
       "        0.3994])"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6056)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out how wrong our predictions are\n",
    "loss = torch.abs(preds - t_dep).mean()\n",
    "loss\n",
    "\n",
    "# Ideally loss should be 0, it is a value between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the functions for calculating predictions and loss\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    return (indeps*coeffs).sum(axis=1)\n",
    "\n",
    "def calc_loss(coeffs, indeps, deps):\n",
    "    return torch.abs(calc_preds(coeffs, indeps) - deps).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Doing a gradient descent step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3823,  0.4150, -0.1171,  0.4593, -0.1096,  0.1009, -0.2434,  0.2936,\n",
       "         0.4408, -0.3668,  0.4346,  0.0936], requires_grad=True)"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()         # Tracks the operation of the tensor, used in Backpropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6056, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()         # Performing Backpropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0883,  0.0272,  0.0056,  0.0608,  0.3423, -0.0853, -0.1324,  0.0202,\n",
       "         0.3692, -0.0786,  0.0842,  0.2514])"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.grad             # E.g. tells us that if we reduce the age, we will be closer to the actual/expected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As most values are positive in the coeffs tensor, we perform subtraction as our aim is to push the loss value closer to 0\n",
    "with torch.no_grad():\n",
    "    coeffs.sub_(coeffs.grad * 0.1)          # new_coeffs=old_coeffs−learning_rate×∇loss\n",
    "    # .sub_ performs subtraction in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5696, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(calc_loss(coeffs, t_indep, t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the Linear Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing set\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "\n",
    "trn_split, val_split = RandomSplitter(seed=42)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep, val_indep = t_indep[trn_split], t_indep[val_split]\n",
    "trn_dep, val_dep = t_dep[trn_split], t_dep[val_split]\n",
    "\n",
    "len(trn_indep), len(val_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the coefficients\n",
    "def update_coeffs(coeffs, lr):\n",
    "    coeffs.sub_(coeffs.grad * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function has all the steps we need to perform in every epoch\n",
    "\n",
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the coefficients\n",
    "def init_coeffs():\n",
    "    return (torch.rand(n_coeff)-0.5).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(epochs=30, lr=0.01):\n",
    "    torch.manual_seed(42)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs):\n",
    "        one_epoch(coeffs, lr=lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603; 0.598; 0.587; 0.571; 0.551; 0.526; 0.497; 0.466; 0.435; 0.405; 0.397; 0.418; 0.439; 0.451; 0.451; 0.438; 0.414; 0.385; 0.371; 0.376; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(epochs=20, lr=0.015)\n",
    "\n",
    "# As we can see the loss decreases from 0.603 from the 1st epoch to 0.376 after the 20th epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(0.3836),\n",
       " 'SibSp': tensor(0.3705),\n",
       " 'Parch': tensor(-0.1031),\n",
       " 'LogFare': tensor(0.6025),\n",
       " 'Sex_male': tensor(-0.4575),\n",
       " 'Sex_female': tensor(0.4583),\n",
       " 'Pclass_1': tensor(0.2893),\n",
       " 'Pclass_2': tensor(0.3114),\n",
       " 'Pclass_3': tensor(-0.1002),\n",
       " 'Embarked_C': tensor(-0.0082),\n",
       " 'Embarked_Q': tensor(0.2484),\n",
       " 'Embarked_S': tensor(-0.0693)}"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to return coefficients and their values\n",
    "def show_coeffs():\n",
    "    return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "\n",
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing some of the results above....\n",
    "\n",
    "`Pclass_1` and `Pclass_2` value being >0 indicate that passengers belonging to 1st or 2nd class had **higher than average** chances of survival\n",
    "`Pclass3` value being <0 indicates that passengers belonging to 3rd class had **lower than average** chances of survival\n",
    "\n",
    "NOTE that this 'analysis' **may not be completely accurate**, especially considering the loss is still pretty high at 0.376. E.g. the results indicate that older people had a significantly higher chance of survival, but that is false.\n",
    "\n",
    "So, it is a good practice to glance through this data, but one should avoid forming conclusions based on this data, yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Measuring Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predictions\n",
    "preds = calc_preds(coeffs, val_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False,  True,  True, False,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_dep.bool() == (preds>0.5)     # pred is a value between 0 and 1, pred>0.5 indicates the prediction edging towards the passenger surviving\n",
    "results[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 1st 20 predictions, we are correct 4/20 times. This gives us a 80% accuracy.\n",
    "\n",
    "This is just a calculation based on the first 20 samples and may not reflect the accuracy for the complete dataset. (E.g. if we took only the 1st 10 values, ee would have 100% accuracy, which is not true.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7865)"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.float().mean()          # We are right 78% of the time\n",
    "# Result stores 1 (True) for a correct prediction and 0 (False) for a wrong prediction, so, we can use results.float().mean() to find the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a function to calculate accuracy\n",
    "def acc(coeffs):\n",
    "    return (val_dep.bool() == (calc_preds(coeffs, val_indep)>0.5)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using Sigmoids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3833,  0.0151, -0.2473,  0.2871,  0.1593,  0.2924,  0.6095,  1.0895,\n",
       "        -0.0514,  0.7983, -0.2621, -0.1525, -0.3376,  0.9324, -0.2694,  0.2985,\n",
       "         0.3944,  1.1213,  0.2898,  0.6568])"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, sometimes we are getting values < 0 or > 1, which shouldn't happen as 0 indicates didn't survive and 1 indicates survive.\n",
    "\n",
    "We need to squash all the values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sympy.plotting.plot.Plot at 0x243f473fbe0>"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.plot(\"1/(1+exp(-x))\", xlim=(-10, 10))         # Plotting the function for the values between -10 and 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations about the function from it's graph:\n",
    "1. It is pretty close to a straight line between 0 and 1 (our desired range)\n",
    "2. It is very close to 0 for values < -5\n",
    "3. It is very close to 1 for values > 5\n",
    "\n",
    "Therefore, this is an ideal function for our usecase. It is called the **sigmoid function**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch already has an inbuilt sigmoid() function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining calc_preds and using the sigmoid function\n",
    "def calc_preds(coeffs, indeps):\n",
    "    return torch.sigmoid((indeps*coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-training the model using a different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546; 0.510; 0.432; 0.344; 0.297; 0.276; 0.260; 0.245; 0.230; 0.218; 0.210; 0.205; 0.202; 0.201; 0.200; 0.199; 0.199; 0.199; 0.199; 0.199; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(epochs= 20, lr=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate decreased to 0.199, this is a huge improvement on using a learning rate of 0.015!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)             # Our accuracy increased to 82.58%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.9615),\n",
       " 'SibSp': tensor(-0.1795),\n",
       " 'Parch': tensor(-0.0275),\n",
       " 'LogFare': tensor(1.4206),\n",
       " 'Sex_male': tensor(-13.5629),\n",
       " 'Sex_female': tensor(11.0366),\n",
       " 'Pclass_1': tensor(4.3148),\n",
       " 'Pclass_2': tensor(1.9842),\n",
       " 'Pclass_3': tensor(-8.3257),\n",
       " 'Embarked_C': tensor(1.4056),\n",
       " 'Embarked_Q': tensor(0.4748),\n",
       " 'Embarked_S': tensor(-4.2367)}"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submitting to Kaggle** (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle provides a seperate test.csv file which has seperate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing all the transformations we made on training set on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the rows in the testing set has an empty Fare column (NA), even though none of the Fare values were NA in the testing dataset, so we fill the single NA column in the test set with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'] = test_df.Fare.fillna(0)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.fillna(modes, inplace=True)\n",
    "test_df['LogFare'] = np.log(test_df['Fare']+1)\n",
    "test_df = pd.get_dummies(test_df, columns=[\"Sex\", \"Pclass\", \"Embarked\"])\n",
    "\n",
    "test_indep = tensor(test_df[indep_cols].values, dtype=torch.float)\n",
    "tst_indep = test_indep/vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Survived\"] = (calc_preds(test_indep, coeffs)>0.5).int()        # .int() rounds off the values so we either have a 0 for didn't survive or 1 for survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe with only 2 columns: PassengerId and Survived, for submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = test_df[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('sub.csv', index=False)           # to_csv method creates an index by default, we don't want an index so we set index to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is saved as `sub.csv`, you can access it from the base path folder and submit it to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Matrix Multiplication**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'*' - element wise multiplication\n",
    "'@' - matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 13.7970, -21.2089, -20.2916, -15.0504, -15.5151, -15.5428,   4.6713,\n",
       "          9.0484, -25.3779,   4.5183, -26.0116, -20.1638, -25.6322,   3.3943,\n",
       "        -26.0754, -13.2708, -13.5112,   9.2293, -15.5339,  -1.3815, -25.9162,\n",
       "        -13.4030,  17.3351,   9.1294, -25.8909, -20.9906,  -0.9966, -13.4751,\n",
       "        -25.8133,   3.3910,   9.1594,  -0.9587, -25.8561, -25.9904,  13.7249,\n",
       "         -0.8578, -13.2402,  17.4366, -25.9123,  -1.3504, -15.4878, -25.9123,\n",
       "        -15.5130,  17.3621, -25.8642,  -1.1979, -25.5155, -25.6922, -21.2304,\n",
       "         -1.3098,  -8.3202, -25.4740, -25.5407, -25.9510, -15.5719, -15.6440,\n",
       "        -21.2085, -25.9416, -25.8763, -25.8215,  -7.4385, -25.8771, -13.6646,\n",
       "        -25.8794,   8.9831, -12.7492, -15.5031, -25.8599, -21.2835,   8.8520,\n",
       "        -25.9403,   4.4535, -15.6320, -25.8785, -13.0236, -25.8232, -25.9123,\n",
       "        -12.9371, -15.4430, -15.7491, -15.0371,  17.7193, -25.9042, -25.9334,\n",
       "          8.7392,  -9.6512,  -7.0115,  12.0065,  14.8002, -15.4911, -26.0007,\n",
       "        -25.9123,  17.4611, -20.3637,   4.7429, -10.0070, -15.6180,   3.5781,\n",
       "          3.4150, -21.1761, -25.8722,   3.3910, -26.0124, -25.9883, -12.9555,\n",
       "        -15.7194, -25.9506,   9.1161,  -7.1359, -26.0216,   9.1286,  -1.2505,\n",
       "        -12.9916,  16.4339, -25.9123,  17.0000,  -1.3271, -21.2085, -26.1389,\n",
       "         17.4070, -25.5683,  -7.5926, -21.2085,  -0.8931, -20.2917, -13.0517,\n",
       "         -1.3318,  -1.3418, -25.7823, -15.6164,  11.9403, -25.7899,   9.0793,\n",
       "          8.9943,  17.5829, -25.8522, -15.9157, -25.9389,  -9.8039,   9.0671,\n",
       "        -15.5752,  17.1050, -26.1935, -21.3047,  -1.1404,  11.3296, -26.0657,\n",
       "          4.5362,  11.7598,   4.1944,  -1.1167,   3.3818,   9.0877, -20.8291,\n",
       "        -21.0214, -25.6335, -25.9123,  -1.2464, -15.6233, -25.7898,  17.3614,\n",
       "         -9.7797, -25.7435, -12.8574,  17.2523,  11.8130,   9.2384,   8.8801,\n",
       "        -13.0255, -13.3605,  -0.8606, -25.7297,  11.7870, -25.8785, -26.1559,\n",
       "         11.6464, -12.9879, -25.6169])"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_indep * coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 13.7970, -21.2089, -20.2916, -15.0504, -15.5151, -15.5428,   4.6713,\n",
       "          9.0484, -25.3779,   4.5183, -26.0116, -20.1638, -25.6322,   3.3943,\n",
       "        -26.0754, -13.2708, -13.5112,   9.2293, -15.5339,  -1.3815, -25.9162,\n",
       "        -13.4030,  17.3351,   9.1294, -25.8909, -20.9906,  -0.9966, -13.4751,\n",
       "        -25.8133,   3.3910,   9.1594,  -0.9587, -25.8561, -25.9904,  13.7249,\n",
       "         -0.8578, -13.2402,  17.4366, -25.9123,  -1.3504, -15.4878, -25.9123,\n",
       "        -15.5130,  17.3621, -25.8642,  -1.1979, -25.5155, -25.6922, -21.2304,\n",
       "         -1.3098,  -8.3202, -25.4740, -25.5407, -25.9510, -15.5719, -15.6440,\n",
       "        -21.2085, -25.9416, -25.8763, -25.8215,  -7.4385, -25.8771, -13.6646,\n",
       "        -25.8794,   8.9831, -12.7492, -15.5031, -25.8599, -21.2835,   8.8520,\n",
       "        -25.9403,   4.4535, -15.6320, -25.8785, -13.0236, -25.8232, -25.9123,\n",
       "        -12.9371, -15.4430, -15.7491, -15.0371,  17.7193, -25.9042, -25.9334,\n",
       "          8.7392,  -9.6512,  -7.0115,  12.0065,  14.8002, -15.4911, -26.0007,\n",
       "        -25.9123,  17.4611, -20.3637,   4.7429, -10.0070, -15.6180,   3.5781,\n",
       "          3.4150, -21.1761, -25.8722,   3.3910, -26.0124, -25.9883, -12.9555,\n",
       "        -15.7194, -25.9506,   9.1161,  -7.1359, -26.0216,   9.1286,  -1.2505,\n",
       "        -12.9916,  16.4339, -25.9123,  17.0000,  -1.3271, -21.2085, -26.1389,\n",
       "         17.4070, -25.5683,  -7.5926, -21.2085,  -0.8931, -20.2917, -13.0517,\n",
       "         -1.3318,  -1.3418, -25.7823, -15.6164,  11.9403, -25.7899,   9.0793,\n",
       "          8.9943,  17.5829, -25.8522, -15.9157, -25.9389,  -9.8039,   9.0671,\n",
       "        -15.5752,  17.1050, -26.1935, -21.3047,  -1.1404,  11.3296, -26.0657,\n",
       "          4.5362,  11.7598,   4.1944,  -1.1167,   3.3818,   9.0877, -20.8291,\n",
       "        -21.0214, -25.6335, -25.9123,  -1.2464, -15.6233, -25.7898,  17.3614,\n",
       "         -9.7797, -25.7435, -12.8574,  17.2523,  11.8130,   9.2384,   8.8801,\n",
       "        -13.0255, -13.3605,  -0.8606, -25.7297,  11.7870, -25.8785, -26.1559,\n",
       "         11.6464, -12.9879, -25.6169])"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indep @ coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get the same values either way....\n",
    "\n",
    "We normally use matrix multiplication as it is more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can rewrite the calc_preds function to use matrix multiplication\n",
    "def calc_preds(coeffs, indep):\n",
    "    return torch.sigmoid(indep @ coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting the init_coeffs function to define the initial coefficient as a matrix instead of a vector, which is needed as we're going to create a neural network\n",
    "def init_coeffs():\n",
    "    return (torch.rand(n_coeff, 1) * 1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([713])"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding None creates an extra dimension, converting it from a vector to a matrix\n",
    "trn_dep = trn_dep[: , None]\n",
    "val_dep = val_dep[: , None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([713, 1])"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dep.shape                   # Now it is a matrix with 713 rows and 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605; 0.602; 0.594; 0.578; 0.542; 0.463; 0.342; 0.270; 0.256; 0.258; 0.261; 0.260; 0.255; 0.244; 0.231; 0.219; 0.210; 0.204; 0.201; 0.199; 0.197; 0.196; 0.196; 0.195; 0.195; 0.196; 0.196; 0.196; 0.197; 0.197; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model\n",
    "coeffs = train_model(lr=2)\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):               # n_hidden indicates the number of hidden neurons\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden       # We divide by n_hidden to avoid the numbers from being too big, as the model won't train if the numbers are too big or too small\n",
    "    layer2 = torch.rand(n_hidden, 1) - 0.3          # 0.3 is an experimental value, model trains when we subtract it by 0.3\n",
    "    const = torch.rand(1)[0]            # Creating a constant term\n",
    "    return layer1.requires_grad_(), layer2.requires_grad_(), const.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    l1, l2, const = coeffs              # l1 l2 are the weights while const is the constant\n",
    "    res = F.relu(indeps @ l1)           # 1st layer - we perform matrix multiplication and apply the activation function - ReLU\n",
    "    res = res @ l2 + const              # 2nd layer - we perform matrix multiplication and add the constant\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    # As we have multiple (3) layers, we need to go through each one of them in a for loop\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550; 0.543; 0.530; 0.504; 0.458; 0.388; 0.332; 0.314; 0.287; 0.230; 0.208; 0.212; 0.214; 0.215; 0.215; 0.215; 0.215; 0.214; 0.214; 0.215; 0.215; 0.214; 0.213; 0.214; 0.214; 0.214; 0.214; 0.214; 0.214; 0.214; "
     ]
    }
   ],
   "source": [
    "# Training our model\n",
    "coeffs = train_model(lr=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7921)"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deep Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    hiddens = [10, 10]              # 2 hidden layers with 10 neurons each\n",
    "    sizes = [n_coeff] + hiddens + [1]           # Represents the number of neurons in each layer\n",
    "    n = len(sizes)              # Represents the number of layers\n",
    "    \n",
    "    layers = [(torch.rand(sizes[i+1]) - 0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    # Initializes the weights for each layer, sizes[i+1] represents the number of neurons in the next layer and 4 is a scaling factor used to facilitate learning\n",
    "    \n",
    "    consts = [(torch.rand(1)[0] - 0.5) * 0.1 for i in range(n-1)]       # Setting constants values \n",
    "    # range is always n-1 as we do not need constants for the output layer\n",
    "    \n",
    "    for l in layers+consts:\n",
    "        l.requires_grad_()              # Setting up requires_grad_ for each layer and constant\n",
    "        \n",
    "    return layers, consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    layers, consts = coeffs\n",
    "    n = len(layers)         # Number of layers\n",
    "    res = indeps\n",
    "    for i, l in enumerate(layers):\n",
    "        res = (res @ l) + consts[i]         # Calculating the result for each layer\n",
    "        if i!=n-1:              # For every layer except the output layer, we apply the ReLU activation function\n",
    "            res = F.relu(res)\n",
    "    return torch.sigmoid(res)           # Returning the result after applying the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    layers, consts = coeffs\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad * lr)             # Updating the layers and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got input (713), mat (713x12), vec (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [883]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [848]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(epochs, lr)\u001b[0m\n\u001b[0;32m      4\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m init_coeffs()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mone_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coeffs\n",
      "Input \u001b[1;32mIn [846]\u001b[0m, in \u001b[0;36mone_epoch\u001b[1;34m(coeffs, lr)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_epoch\u001b[39m(coeffs, lr):\n\u001b[1;32m----> 4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_indep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_dep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Input \u001b[1;32mIn [836]\u001b[0m, in \u001b[0;36mcalc_loss\u001b[1;34m(coeffs, indeps, deps)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_loss\u001b[39m(coeffs, indeps, deps):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mabs(\u001b[43mcalc_preds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindeps\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m deps)\u001b[38;5;241m.\u001b[39mmean()\n",
      "Input \u001b[1;32mIn [881]\u001b[0m, in \u001b[0;36mcalc_preds\u001b[1;34m(coeffs, indeps)\u001b[0m\n\u001b[0;32m      6\u001b[0m res \u001b[38;5;241m=\u001b[39m indeps\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layers):\n\u001b[1;32m----> 8\u001b[0m     res \u001b[38;5;241m=\u001b[39m (\u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m) \u001b[38;5;241m+\u001b[39m consts[i]         \u001b[38;5;66;03m# Calculating the result for each layer\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m!=\u001b[39mn\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:              \u001b[38;5;66;03m# For every layer except the output layer, we apply the ReLU activation function\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         res \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(res)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, got input (713), mat (713x12), vec (10)"
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
